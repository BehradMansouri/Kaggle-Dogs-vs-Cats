# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14ywrX2W-oXG91nPc4em8aDV6qUYLrMfk
"""

import os
import zipfile

!wget https://storage.googleapis.com/tensorflow-1-public/course2/cats_and_dogs_filtered.zip


zip_ref = zipfile.ZipFile("./cats_and_dogs_filtered.zip", 'r')
zip_ref.extractall("tmp/")
zip_ref.close()

base_dir = 'tmp/cats_and_dogs_filtered'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation')

train_cats_dir = os.path.join(train_dir, 'cats')
train_dogs_dir = os.path.join(train_dir, 'dogs')

validation_cats_dir = os.path.join(validation_dir, 'cats')
validation_dogs_dir = os.path.join(validation_dir, 'dogs')

import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras import initializers

def create_model():
  model = tf.keras.models.Sequential([
      tf.keras.layers.Conv2D(64, (3,3), data_format="channels_last", activation='relu', input_shape=(380, 380, 3)),
      #tf.keras.layers.BatchNormalization(axis=-1),
      tf.keras.layers.Dropout(0.01),
      tf.keras.layers.Conv2D(64, (3,3), data_format="channels_last", activation='relu'),
      tf.keras.layers.BatchNormalization(axis=-1),
      tf.keras.layers.MaxPooling2D(2, 2),
      tf.keras.layers.Conv2D(128, (3,3), data_format="channels_last", activation='relu'),
      #tf.keras.layers.BatchNormalization(axis=-1),
      tf.keras.layers.Dropout(0.02),
      tf.keras.layers.Conv2D(128, (3,3), data_format="channels_last", activation='relu'),
      tf.keras.layers.BatchNormalization(axis=-1),
      tf.keras.layers.MaxPooling2D(2,2),
      tf.keras.layers.Conv2D(256, (3,3), data_format="channels_last", activation='relu'),
      #tf.keras.layers.BatchNormalization(axis=-1),
      tf.keras.layers.Dropout(0.03),
      tf.keras.layers.Conv2D(256, (3,3), data_format="channels_last", activation='relu'),
      tf.keras.layers.BatchNormalization(axis=-1),
      tf.keras.layers.MaxPooling2D(2,2),
      #tf.keras.layers.Conv2D(512, (3,3), data_format="channels_last", activation='relu'),
      tf.keras.layers.Conv2D(384, (3,3), data_format="channels_last", activation='relu'),
      #tf.keras.layers.BatchNormalization(axis=-1),
      tf.keras.layers.Dropout(0.04),
      #tf.keras.layers.Conv2D(512, (3,3), data_format="channels_last", activation='relu'),
      tf.keras.layers.Conv2D(384, (3,3), data_format="channels_last", activation='relu'),
      tf.keras.layers.BatchNormalization(axis=-1),
      tf.keras.layers.MaxPooling2D(2,2),
      tf.keras.layers.Flatten(),
#      tf.keras.layers.Conv2D(64, (3,3), data_format="channels_last", activation=tf.keras.layers.LeakyReLU(alpha=0.3)),
      #tf.keras.layers.Dropout(0.2),
      #tf.keras.layers.Dropout(0.1),
      tf.keras.layers.Dropout(0.08),
      #tf.keras.layers.Dense(1000, activation='relu', activity_regularizer=tf.keras.regularizers.L2(2e-5)),
      #tf.keras.layers.Dense(1000, activation='relu', activity_regularizer=tf.keras.regularizers.L2(1e-6)),
      #tf.keras.layers.Dense(1024, activation='relu'),
      #tf.keras.layers.Dense(512, activation='relu'),
      #tf.keras.layers.Dense(600, activation='relu', activity_regularizer=tf.keras.regularizers.L2(1e-4)),
      tf.keras.layers.Dense(600, activation='relu', activity_regularizer=tf.keras.regularizers.L2(2e-5)),
                                #tf.keras.layers.BatchNormalization(),
      tf.keras.layers.Dense(25, activation='relu', activity_regularizer=tf.keras.regularizers.L2(1e-7)),
                  #tf.keras.layers.Dense(71, activation='relu', activity_regularizer=tf.keras.regularizers.L2(2e-7)),
                  #tf.keras.layers.Dense(9, activation='relu'),
              #tf.keras.layers.BatchNormalization(scale=True, gamma_initializer=2),
              #initializer=tf.keras.initializers.Constant(2.),
              #tf.keras.layers.BatchNormalization(scale=True, gamma_initializer=initializer),
      #tf.keras.layers.Dense(1, activation='sigmoid')
      tf.keras.layers.Dense(2, activation='softmax')
  ])

  #model.compile(loss='binary_crossentropy',
  model.compile(loss='categorical_crossentropy',
                optimizer=RMSprop(learning_rate=1e-4),
                #optimizer=RMSprop(learning_rate=5e-5),
                #optimizer=RMSprop(learning_rate=1e-5),
                metrics=['accuracy'])
  
  return model

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
      rescale=1./255,
      rotation_range=40,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest')

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
        train_dir,
        #target_size=(188, 188),
        target_size=(380, 380),
        batch_size=20,
        #batch_size=100,
        #class_mode='binary')
        class_mode='categorical')

validation_generator = test_datagen.flow_from_directory(
        validation_dir,
        #target_size=(188, 188),
        target_size=(380, 380),
        batch_size=20,
        #batch_size=100,
        #class_mode='binary')
        class_mode='categorical')

EPOCHS = 100

model_for_aug = create_model()

my_callbacks = [
                        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.4, patience=4, verbose=1, min_delta=0.0001, cooldown=0, min_lr=1e-6)
    #tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=7, verbose=1, min_delta=0.0001, cooldown=0, min_lr=2e-6)
    #tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=10, verbose=1, min_delta=0.0001, cooldown=0, min_lr=2e-6)
]

history_1 = model_for_aug.fit(
      train_generator,
      steps_per_epoch=100,
      #steps_per_epoch=20,
      epochs=EPOCHS,
      callbacks=my_callbacks,
      validation_data=validation_generator,
      validation_steps=50,
      #validation_steps=10,
      verbose=2)

import matplotlib.pyplot as plt

def plot_loss_acc(history):
  acc = history.history['accuracy']
  val_acc = history.history['val_accuracy']
  loss = history.history['loss']
  val_loss = history.history['val_loss']

  epochs = range(len(acc))

  plt.plot(epochs, acc, 'bo', label='Training accuracy')
  plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
  plt.title('Training and validation accuracy')

  plt.figure()

  plt.plot(epochs, loss, 'bo', label='Training Loss')
  plt.plot(epochs, val_loss, 'b', label='Validation Loss')
  plt.title('Training and validation loss')
  plt.legend()

  plt.show()

plot_loss_acc(history_1)